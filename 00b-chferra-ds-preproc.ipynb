{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10202572,"sourceType":"datasetVersion","datasetId":6304906},{"sourceId":10389539,"sourceType":"datasetVersion","datasetId":6436731}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport nrrd\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\nimport shutil","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T11:22:48.032286Z","iopub.execute_input":"2025-01-11T11:22:48.032867Z","iopub.status.idle":"2025-01-11T11:22:48.997855Z","shell.execute_reply.started":"2025-01-11T11:22:48.032810Z","shell.execute_reply":"2025-01-11T11:22:48.996641Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"excel_file_path = \"/kaggle/input/lung-tumor-ds/dataset_lung.xlsx\" \ntrain_folder = \"/kaggle/input/lung-tumor-ds/Train\" \n\noutput_dir = \"/kaggle/working/lung-ds\"\noutput_folder_full_slice = os.path.join(output_dir, \"Full_slice\")\noutput_folder_nodule = os.path.join(output_dir, \"Nodule\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T11:22:48.999306Z","iopub.execute_input":"2025-01-11T11:22:48.999843Z","iopub.status.idle":"2025-01-11T11:22:49.004705Z","shell.execute_reply.started":"2025-01-11T11:22:48.999813Z","shell.execute_reply":"2025-01-11T11:22:49.003530Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"if os.path.exists(output_dir):\n    shutil.rmtree(output_dir)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T11:22:49.006307Z","iopub.execute_input":"2025-01-11T11:22:49.006695Z","iopub.status.idle":"2025-01-11T11:22:49.021418Z","shell.execute_reply.started":"2025-01-11T11:22:49.006665Z","shell.execute_reply":"2025-01-11T11:22:49.020369Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"df = pd.read_excel(excel_file_path)\ndf['TumorClass'] = df['TumorClass'] - 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T11:22:49.023246Z","iopub.execute_input":"2025-01-11T11:22:49.023714Z","iopub.status.idle":"2025-01-11T11:22:49.607791Z","shell.execute_reply.started":"2025-01-11T11:22:49.023666Z","shell.execute_reply":"2025-01-11T11:22:49.606675Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def balance_classes(df, label_column):\n    class_counts = df[label_column].value_counts()\n    print(\"Original class distribution:\")\n    print(class_counts)\n\n    # Determine thresholds\n    max_target = int(class_counts.mean())  # Downsample majority classes to mean size\n    min_target = int(class_counts.mean())  # Upsample minority classes to mean size\n\n    dfs = []\n\n    for label in df[label_column].unique():\n        label_data = df[df[label_column] == label]\n        current_count = len(label_data)\n\n        if current_count > max_target:\n            # Downsample majority class\n            downsampled_data = resample(\n                label_data,\n                replace=False,  # Sample without replacement\n                n_samples=max_target,\n                random_state=42\n            )\n            dfs.append(downsampled_data)\n\n        elif current_count < min_target:\n            # Upsample minority class\n            upsampled_data = resample(\n                label_data,\n                replace=True,  # Sample with replacement\n                n_samples=min_target,\n                random_state=42\n            )\n            dfs.append(upsampled_data)\n\n        else:\n            # Keep as is\n            dfs.append(label_data)\n\n    # Combine balanced data\n    df_balanced = pd.concat(dfs)\n\n    # Shuffle the dataset\n    df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n\n    # Verify new distribution\n    print(\"\\nBalanced class distribution:\")\n    print(df_balanced[label_column].value_counts())\n\n    return df_balanced\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T11:22:49.608768Z","iopub.execute_input":"2025-01-11T11:22:49.609303Z","iopub.status.idle":"2025-01-11T11:22:49.616937Z","shell.execute_reply.started":"2025-01-11T11:22:49.609263Z","shell.execute_reply":"2025-01-11T11:22:49.615703Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def gamma_transform(image, lower_bound, upper_bound, gamma):\n    clipped_image    = np.clip(image, lower_bound, upper_bound)\n    hu_min = np.min(clipped_image)\n    hu_max = np.max(clipped_image)\n    normalized_image = (clipped_image - hu_min) / (hu_max - hu_min) # Normalize to [0, 1]\n    gamma_corrected  = np.power(normalized_image, gamma) # Apply gamma transformation\n    gamma_corrected  = gamma_corrected * (hu_max - hu_min) + hu_min # Scale back to the original HU range\n    return gamma_corrected\n\ndef need_gamma_transformation(image, intensity_threshold, cdf_threshold=0.8):\n    hist, bin_edges = np.histogram(image.ravel(), bins=256)\n    cdf = np.cumsum(hist) / np.sum(hist)\n    idx = (np.abs(bin_edges - (intensity_threshold))).argmin()\n    if cdf[idx] >= cdf_threshold:\n        return True\n    else:\n        return False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T11:22:49.618018Z","iopub.execute_input":"2025-01-11T11:22:49.618285Z","iopub.status.idle":"2025-01-11T11:22:49.637328Z","shell.execute_reply.started":"2025-01-11T11:22:49.618261Z","shell.execute_reply":"2025-01-11T11:22:49.636440Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def get_unique_filename(save_path):\n    base, ext = os.path.splitext(save_path)\n    counter = 0\n    unique_path = save_path\n\n    while os.path.exists(unique_path):\n        unique_path = f\"{base}_{counter}{ext}\"\n        counter += 1\n\n    return unique_path\n\nintensity_threshold_fs = 10\ncdf_threshold_fs = 0.6\ngamma_fs = 1.35\nlb_fs = -1200\nup_fs = 1000\n\nintensity_threshold_nd = -600\ncdf_threshold_nd = 0.8\ngamma_nd = 1.35\nlb_nd = -800\nup_nd = 0\n\n\ndef convert_nrrd_to_image(nrrd_path, save_path, image_column, resize_to=None):\n    data, header = nrrd.read(nrrd_path)\n\n    # Clip and normalize the data\n    #hu_min, hu_max = -1000, 400\n    #data_clipped = np.clip(data, hu_min, hu_max)\n    #normalized = (data_clipped - hu_min) / (hu_max - hu_min)\n\n    if image_column == \"Full_slice\":\n        intensity_threshold, cdf_threshold, gamma, lb, ub = (\n            intensity_threshold_fs,\n            cdf_threshold_fs,\n            gamma_fs,\n            lb_fs,\n            up_fs\n        )\n    elif image_column == \"Nodule\":\n        intensity_threshold, cdf_threshold, gamma, lb, ub = (\n            intensity_threshold_nd,\n            cdf_threshold_nd,\n            gamma_nd,\n            lb_nd,\n            up_nd\n        )\n    else: \n        raise ValueError('Nor full_slice or nodule type provided.')\n\n    image_status = need_gamma_transformation(data, intensity_threshold, cdf_threshold)\n    transformed_image = None\n    if image_status:\n        transformed_image = gamma_transform(data, lb, ub, gamma)\n    else:\n        transformed_image = data\n\n    grayscale_image = (transformed_image * 255).astype(np.uint8)\n    rgb_image = np.stack([grayscale_image] * 3, axis=-1)\n\n    pil_image = Image.fromarray(rgb_image)\n\n    if resize_to is not None:\n        pil_image = pil_image.resize(resize_to)\n\n    unique_save_path = get_unique_filename(save_path)\n\n    pil_image.save(unique_save_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T11:22:49.638472Z","iopub.execute_input":"2025-01-11T11:22:49.638855Z","iopub.status.idle":"2025-01-11T11:22:49.660182Z","shell.execute_reply.started":"2025-01-11T11:22:49.638817Z","shell.execute_reply":"2025-01-11T11:22:49.659126Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def create_imagefolder_dataset_with_split(df, image_column, label_column, output_folder, source_folder, train_ratio=0.8, resize_to=None):\n    train_folder = os.path.join(output_folder, \"train\")\n    val_folder = os.path.join(output_folder, \"val\")      \n    \n    os.makedirs(train_folder, exist_ok=True)\n    os.makedirs(val_folder, exist_ok=True)\n\n    # Group by label and split\n    for label in df[label_column].unique():\n        label_data = df[df[label_column] == label]\n\n        train_data, val_data = train_test_split(label_data, test_size=1-train_ratio, random_state=42)\n\n        # Create label subfolders\n        train_label_folder = os.path.join(train_folder, str(label))\n        val_label_folder = os.path.join(val_folder, str(label))\n        os.makedirs(train_label_folder, exist_ok=True)\n        os.makedirs(val_label_folder, exist_ok=True)\n\n        print(train_data.shape)\n\n        counterTrain = 0\n        counterVal = 0\n\n        # Save images to respective folders\n        for _, row in train_data.iterrows():\n            nrrd_name = row[image_column]\n            source_path = os.path.join(source_folder, nrrd_name)\n            dest_path = os.path.join(train_label_folder, nrrd_name.replace('.nrrd', '.png'))\n            convert_nrrd_to_image(source_path, dest_path, image_column, resize_to=resize_to)\n            counterTrain += 1\n\n        for _, row in val_data.iterrows():\n            nrrd_name = row[image_column]\n            source_path = os.path.join(source_folder, nrrd_name)\n            dest_path = os.path.join(val_label_folder, nrrd_name.replace('.nrrd', '.png'))\n            convert_nrrd_to_image(source_path, dest_path, image_column, resize_to=resize_to)\n            counterVal += 1\n\n        print(counterTrain)\n        print(counterVal)\n\n    print(f\"Train/val split dataset created in {output_folder}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T11:22:49.662493Z","iopub.execute_input":"2025-01-11T11:22:49.662850Z","iopub.status.idle":"2025-01-11T11:22:49.681881Z","shell.execute_reply.started":"2025-01-11T11:22:49.662821Z","shell.execute_reply":"2025-01-11T11:22:49.680869Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"df_balanced = balance_classes(df, label_column=\"TumorClass\")\n\ncreate_imagefolder_dataset_with_split(\n    df=df_balanced,\n    image_column=\"Full_slice\",\n    label_column=\"TumorClass\",\n    output_folder=output_folder_full_slice,\n    source_folder=train_folder\n)\n\ncreate_imagefolder_dataset_with_split(\n    df=df_balanced,\n    image_column=\"Nodule\",\n    label_column=\"TumorClass\",\n    output_folder=output_folder_nodule,\n    source_folder=train_folder,\n    resize_to=(96, 96)\n    \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T11:22:49.683113Z","iopub.execute_input":"2025-01-11T11:22:49.683405Z","iopub.status.idle":"2025-01-11T11:27:45.645739Z","shell.execute_reply.started":"2025-01-11T11:22:49.683368Z","shell.execute_reply":"2025-01-11T11:27:45.644606Z"}},"outputs":[{"name":"stdout","text":"Original class distribution:\nTumorClass\n2    1092\n1     457\n3     418\n0     244\n4     152\nName: count, dtype: int64\n\nBalanced class distribution:\nTumorClass\n1    472\n0    472\n2    472\n4    472\n3    472\nName: count, dtype: int64\n(377, 3)\n377\n95\n(377, 3)\n377\n95\n(377, 3)\n377\n95\n(377, 3)\n377\n95\n(377, 3)\n377\n95\nTrain/val split dataset created in /kaggle/working/lung-ds/Full_slice\n(377, 3)\n377\n95\n(377, 3)\n377\n95\n(377, 3)\n377\n95\n(377, 3)\n377\n95\n(377, 3)\n377\n95\nTrain/val split dataset created in /kaggle/working/lung-ds/Nodule\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"def count_elements_in_folder(folder_path):\n    try:\n        # List all elements in the folder\n        elements = os.listdir(folder_path)\n        \n        # Count the elements\n        count = len(elements)\n        print(f\"The folder '{folder_path}' contains {count} elements.\")\n        return count\n    except FileNotFoundError:\n        print(f\"The folder '{folder_path}' does not exist.\")\n        return 0\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T11:27:45.646844Z","iopub.execute_input":"2025-01-11T11:27:45.647107Z","iopub.status.idle":"2025-01-11T11:27:45.653020Z","shell.execute_reply.started":"2025-01-11T11:27:45.647075Z","shell.execute_reply":"2025-01-11T11:27:45.651981Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import shutil\nshutil.make_archive(\"lung-ds\", 'zip', output_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T11:27:45.654135Z","iopub.execute_input":"2025-01-11T11:27:45.654499Z","iopub.status.idle":"2025-01-11T11:29:19.640824Z","shell.execute_reply.started":"2025-01-11T11:27:45.654459Z","shell.execute_reply":"2025-01-11T11:29:19.639700Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/lung-ds.zip'"},"metadata":{}}],"execution_count":15}]}