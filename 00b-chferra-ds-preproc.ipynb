{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10202572,"sourceType":"datasetVersion","datasetId":6304906}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport nrrd\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\nimport shutil","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T22:57:31.200127Z","iopub.execute_input":"2025-01-06T22:57:31.200475Z","iopub.status.idle":"2025-01-06T22:57:31.205114Z","shell.execute_reply.started":"2025-01-06T22:57:31.200442Z","shell.execute_reply":"2025-01-06T22:57:31.204038Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"excel_file_path = \"/kaggle/input/lung-tumor-ds/dataset_lung.xlsx\" \ntrain_folder = \"/kaggle/input/lung-tumor-ds/Train\" \n\noutput_dir = \"/kaggle/working/lung-ds\"\noutput_folder_full_slice = os.path.join(output_dir, \"Full_slice\")\noutput_folder_nodule = os.path.join(output_dir, \"Nodule\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T22:42:54.136577Z","iopub.execute_input":"2025-01-06T22:42:54.137130Z","iopub.status.idle":"2025-01-06T22:42:54.141887Z","shell.execute_reply.started":"2025-01-06T22:42:54.137098Z","shell.execute_reply":"2025-01-06T22:42:54.140646Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"if os.path.exists(output_dir):\n    shutil.rmtree(output_dir)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T23:26:02.957985Z","iopub.execute_input":"2025-01-06T23:26:02.958307Z","iopub.status.idle":"2025-01-06T23:26:03.148504Z","shell.execute_reply.started":"2025-01-06T23:26:02.958284Z","shell.execute_reply":"2025-01-06T23:26:03.147440Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"df = pd.read_excel(excel_file_path)\ndf['TumorClass'] = df['TumorClass'] - 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T23:03:04.218155Z","iopub.execute_input":"2025-01-06T23:03:04.218606Z","iopub.status.idle":"2025-01-06T23:03:04.421358Z","shell.execute_reply.started":"2025-01-06T23:03:04.218567Z","shell.execute_reply":"2025-01-06T23:03:04.420277Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def balance_classes(df, label_column):\n    class_counts = df[label_column].value_counts()\n    print(\"Original class distribution:\")\n    print(class_counts)\n\n    # Determine thresholds\n    max_target = int(class_counts.mean())  # Downsample majority classes to mean size\n    min_target = int(class_counts.mean())  # Upsample minority classes to mean size\n\n    dfs = []\n\n    for label in df[label_column].unique():\n        label_data = df[df[label_column] == label]\n        current_count = len(label_data)\n\n        if current_count > max_target:\n            # Downsample majority class\n            downsampled_data = resample(\n                label_data,\n                replace=False,  # Sample without replacement\n                n_samples=max_target,\n                random_state=42\n            )\n            dfs.append(downsampled_data)\n\n        elif current_count < min_target:\n            # Upsample minority class\n            upsampled_data = resample(\n                label_data,\n                replace=True,  # Sample with replacement\n                n_samples=min_target,\n                random_state=42\n            )\n            dfs.append(upsampled_data)\n\n        else:\n            # Keep as is\n            dfs.append(label_data)\n\n    # Combine balanced data\n    df_balanced = pd.concat(dfs)\n\n    # Shuffle the dataset\n    df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n\n    # Verify new distribution\n    print(\"\\nBalanced class distribution:\")\n    print(df_balanced[label_column].value_counts())\n\n    return df_balanced\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T23:03:06.235840Z","iopub.execute_input":"2025-01-06T23:03:06.236163Z","iopub.status.idle":"2025-01-06T23:03:06.243720Z","shell.execute_reply.started":"2025-01-06T23:03:06.236140Z","shell.execute_reply":"2025-01-06T23:03:06.242424Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def get_unique_filename(save_path):\n    base, ext = os.path.splitext(save_path)\n    counter = 0\n    unique_path = save_path\n\n    while os.path.exists(unique_path):\n        unique_path = f\"{base}_{counter}{ext}\"\n        counter += 1\n\n    return unique_path\n\ndef convert_nrrd_to_image(nrrd_path, save_path, resize_to=None):\n    data, header = nrrd.read(nrrd_path)\n\n    # Clip and normalize the data\n    hu_min, hu_max = -1000, 400\n    data_clipped = np.clip(data, hu_min, hu_max)\n    normalized = (data_clipped - hu_min) / (hu_max - hu_min)\n\n    # Convert to grayscale and then RGB\n    grayscale_image = (normalized * 255).astype(np.uint8)\n    rgb_image = np.stack([grayscale_image] * 3, axis=-1)\n\n    # Create a PIL image\n    pil_image = Image.fromarray(rgb_image)\n\n    # Resize if needed\n    if resize_to is not None:\n        pil_image = pil_image.resize(resize_to)\n\n    # Ensure the save path is unique\n    unique_save_path = get_unique_filename(save_path)\n\n    # Save the image\n    pil_image.save(unique_save_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T23:25:58.112136Z","iopub.execute_input":"2025-01-06T23:25:58.112511Z","iopub.status.idle":"2025-01-06T23:25:58.119885Z","shell.execute_reply.started":"2025-01-06T23:25:58.112484Z","shell.execute_reply":"2025-01-06T23:25:58.118547Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"def create_imagefolder_dataset_with_split(df, image_column, label_column, output_folder, source_folder, train_ratio=0.8, resize_to=None):\n    train_folder = os.path.join(output_folder, \"train\")\n    val_folder = os.path.join(output_folder, \"val\")      \n    \n    os.makedirs(train_folder, exist_ok=True)\n    os.makedirs(val_folder, exist_ok=True)\n\n    # Group by label and split\n    for label in df[label_column].unique():\n        label_data = df[df[label_column] == label]\n\n        train_data, val_data = train_test_split(label_data, test_size=1-train_ratio, random_state=42)\n\n        # Create label subfolders\n        train_label_folder = os.path.join(train_folder, str(label))\n        val_label_folder = os.path.join(val_folder, str(label))\n        os.makedirs(train_label_folder, exist_ok=True)\n        os.makedirs(val_label_folder, exist_ok=True)\n\n        print(train_data.shape)\n\n        counterTrain = 0\n        counterVal = 0\n\n        # Save images to respective folders\n        for _, row in train_data.iterrows():\n            nrrd_name = row[image_column]\n            source_path = os.path.join(source_folder, nrrd_name)\n            dest_path = os.path.join(train_label_folder, nrrd_name.replace('.nrrd', '.png'))\n            convert_nrrd_to_image(source_path, dest_path, resize_to=resize_to)\n            counterTrain += 1\n\n        for _, row in val_data.iterrows():\n            nrrd_name = row[image_column]\n            source_path = os.path.join(source_folder, nrrd_name)\n            dest_path = os.path.join(val_label_folder, nrrd_name.replace('.nrrd', '.png'))\n            convert_nrrd_to_image(source_path, dest_path, resize_to=resize_to)\n            counterVal += 1\n\n        print(counterTrain)\n        print(counterVal)\n\n    print(f\"Train/val split dataset created in {output_folder}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T23:03:13.009905Z","iopub.execute_input":"2025-01-06T23:03:13.010226Z","iopub.status.idle":"2025-01-06T23:03:13.018716Z","shell.execute_reply.started":"2025-01-06T23:03:13.010203Z","shell.execute_reply":"2025-01-06T23:03:13.017511Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"df_balanced = balance_classes(df, label_column=\"TumorClass\")\n\ncreate_imagefolder_dataset_with_split(\n    df=df_balanced,\n    image_column=\"Full_slice\",\n    label_column=\"TumorClass\",\n    output_folder=output_folder_full_slice,\n    source_folder=train_folder\n)\n\ncreate_imagefolder_dataset_with_split(\n    df=df_balanced,\n    image_column=\"Nodule\",\n    label_column=\"TumorClass\",\n    output_folder=output_folder_nodule,\n    source_folder=train_folder,\n    resize_to=(96, 96)\n    \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T23:26:09.199079Z","iopub.execute_input":"2025-01-06T23:26:09.199540Z","iopub.status.idle":"2025-01-06T23:29:35.909255Z","shell.execute_reply.started":"2025-01-06T23:26:09.199492Z","shell.execute_reply":"2025-01-06T23:29:35.908362Z"}},"outputs":[{"name":"stdout","text":"Original class distribution:\nTumorClass\n2    1092\n1     457\n3     418\n0     244\n4     152\nName: count, dtype: int64\n\nBalanced class distribution:\nTumorClass\n1    472\n0    472\n2    472\n4    472\n3    472\nName: count, dtype: int64\n(377, 3)\n377\n95\n(377, 3)\n377\n95\n(377, 3)\n377\n95\n(377, 3)\n377\n95\n(377, 3)\n377\n95\nTrain/val split dataset created in /kaggle/working/lung-ds/Full_slice\n(377, 3)\n377\n95\n(377, 3)\n377\n95\n(377, 3)\n377\n95\n(377, 3)\n377\n95\n(377, 3)\n377\n95\nTrain/val split dataset created in /kaggle/working/lung-ds/Nodule\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"def count_elements_in_folder(folder_path):\n    try:\n        # List all elements in the folder\n        elements = os.listdir(folder_path)\n        \n        # Count the elements\n        count = len(elements)\n        print(f\"The folder '{folder_path}' contains {count} elements.\")\n        return count\n    except FileNotFoundError:\n        print(f\"The folder '{folder_path}' does not exist.\")\n        return 0\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T23:29:47.798441Z","iopub.execute_input":"2025-01-06T23:29:47.798850Z","iopub.status.idle":"2025-01-06T23:29:47.804068Z","shell.execute_reply.started":"2025-01-06T23:29:47.798819Z","shell.execute_reply":"2025-01-06T23:29:47.802857Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"import shutil\nshutil.make_archive(\"lung-ds\", 'zip', output_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T23:31:12.234983Z","iopub.execute_input":"2025-01-06T23:31:12.235337Z","iopub.status.idle":"2025-01-06T23:31:38.466169Z","shell.execute_reply.started":"2025-01-06T23:31:12.235307Z","shell.execute_reply":"2025-01-06T23:31:38.465120Z"}},"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/lung-ds.zip'"},"metadata":{}}],"execution_count":49}]}