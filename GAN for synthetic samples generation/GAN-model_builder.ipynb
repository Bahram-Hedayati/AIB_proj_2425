{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T15:33:32.586576Z",
     "iopub.status.busy": "2025-02-10T15:33:32.586355Z",
     "iopub.status.idle": "2025-02-10T15:33:45.516830Z",
     "shell.execute_reply": "2025-02-10T15:33:45.515921Z",
     "shell.execute_reply.started": "2025-02-10T15:33:32.586555Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import imageio\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T15:54:58.698010Z",
     "iopub.status.busy": "2025-02-10T15:54:58.697734Z",
     "iopub.status.idle": "2025-02-10T15:55:00.800229Z",
     "shell.execute_reply": "2025-02-10T15:55:00.799485Z",
     "shell.execute_reply.started": "2025-02-10T15:54:58.697990Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1890 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "num_channels = 1\n",
    "num_classes = 5\n",
    "image_size = 512\n",
    "latent_dim = 256 # TUNE\n",
    "\n",
    "data_dir = \"/kaggle/input/lung-ds/Full_slice/train\" ###\n",
    "\n",
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = num_channels + num_classes\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "image_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode=\"grayscale\",\n",
    "    seed=42            \n",
    ")\n",
    "\n",
    "images, labels = next(image_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T16:21:38.948407Z",
     "iopub.status.busy": "2025-02-10T16:21:38.948116Z",
     "iopub.status.idle": "2025-02-10T16:21:38.954876Z",
     "shell.execute_reply": "2025-02-10T16:21:38.954031Z",
     "shell.execute_reply.started": "2025-02-10T16:21:38.948386Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output_dir = \"/kaggle/working\"\n",
    "\n",
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, generator):\n",
    "        super().__init__()\n",
    "        self.generator = generator\n",
    "       \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global latent_dim, num_classes\n",
    "        sample_latent = keras.random.normal(shape=(1, latent_dim), seed=42)\n",
    "        sample_label = tf.one_hot([2], depth=num_classes)  # assuming class 2\n",
    "        sample_input = tf.concat([sample_latent, sample_label], axis=1)\n",
    "\n",
    "        generated_image = self.generator(sample_input, training=False)\n",
    "        generated_image = (generated_image + 1.0) * 127.5\n",
    "        generated_image = tf.cast(generated_image, tf.uint8).numpy()[0, :, :, 0]\n",
    "\n",
    "        imageio.imwrite(f\"{output_dir}/output_epoch_{epoch}.png\", generated_image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-10T16:22:24.810592Z",
     "iopub.status.busy": "2025-02-10T16:22:24.810266Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 126ms/step - d_loss: 0.3491 - g_loss: 3.2003\n",
      "Epoch 2/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.3492 - g_loss: 3.0416\n",
      "Epoch 3/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.1704 - g_loss: 3.6422\n",
      "Epoch 4/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.1722 - g_loss: 4.1231\n",
      "Epoch 5/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.1297 - g_loss: 4.4670\n",
      "Epoch 6/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.1469 - g_loss: 3.6616\n",
      "Epoch 7/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.1818 - g_loss: 3.8173\n",
      "Epoch 8/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.6251 - g_loss: 4.1780\n",
      "Epoch 9/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.1713 - g_loss: 3.7079\n",
      "Epoch 10/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.1919 - g_loss: 3.8371\n",
      "Epoch 11/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.1774 - g_loss: 4.0718\n",
      "Epoch 12/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.1882 - g_loss: 3.9084\n",
      "Epoch 13/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.1683 - g_loss: 3.9340\n",
      "Epoch 14/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.1552 - g_loss: 4.1645\n",
      "Epoch 15/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.1478 - g_loss: 4.2170\n",
      "Epoch 16/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.1327 - g_loss: 4.4924\n",
      "Epoch 17/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.1324 - g_loss: 4.5202\n",
      "Epoch 18/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.1270 - g_loss: 4.4516\n",
      "Epoch 19/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.1253 - g_loss: 4.8193\n",
      "Epoch 20/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.1211 - g_loss: 4.8623\n",
      "Epoch 21/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.1033 - g_loss: 5.1192\n",
      "Epoch 22/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.1079 - g_loss: 5.3364\n",
      "Epoch 23/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0994 - g_loss: 5.3784\n",
      "Epoch 24/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.1221 - g_loss: 5.5257\n",
      "Epoch 25/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.1157 - g_loss: 5.0780\n",
      "Epoch 26/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0926 - g_loss: 5.6655\n",
      "Epoch 27/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0933 - g_loss: 5.4359\n",
      "Epoch 28/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0887 - g_loss: 5.8137\n",
      "Epoch 29/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.1017 - g_loss: 6.2053\n",
      "Epoch 30/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0822 - g_loss: 5.6063\n",
      "Epoch 31/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0643 - g_loss: 6.0556\n",
      "Epoch 32/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.1135 - g_loss: 6.4093\n",
      "Epoch 33/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.1109 - g_loss: 5.6171\n",
      "Epoch 34/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0638 - g_loss: 6.6030\n",
      "Epoch 35/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0621 - g_loss: 6.0483\n",
      "Epoch 36/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.0765 - g_loss: 6.6560\n",
      "Epoch 37/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0708 - g_loss: 6.5783\n",
      "Epoch 38/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0723 - g_loss: 6.8964\n",
      "Epoch 39/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.0638 - g_loss: 6.8122\n",
      "Epoch 40/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0579 - g_loss: 6.9412\n",
      "Epoch 41/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0750 - g_loss: 7.4704\n",
      "Epoch 42/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0751 - g_loss: 7.0350\n",
      "Epoch 43/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.0559 - g_loss: 7.3824\n",
      "Epoch 44/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0862 - g_loss: 7.6814\n",
      "Epoch 45/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0546 - g_loss: 7.9570\n",
      "Epoch 46/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.0591 - g_loss: 7.7425\n",
      "Epoch 47/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0496 - g_loss: 7.4751\n",
      "Epoch 48/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.0847 - g_loss: 8.4606\n",
      "Epoch 49/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0446 - g_loss: 7.8753\n",
      "Epoch 50/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0586 - g_loss: 8.5175\n",
      "Epoch 51/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.0608 - g_loss: 8.4392\n",
      "Epoch 52/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0434 - g_loss: 7.9589\n",
      "Epoch 53/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.1812 - g_loss: 8.7869\n",
      "Epoch 54/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0529 - g_loss: 8.7634\n",
      "Epoch 55/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0346 - g_loss: 8.7545\n",
      "Epoch 56/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0461 - g_loss: 9.1126\n",
      "Epoch 57/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0500 - g_loss: 8.8944\n",
      "Epoch 58/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0502 - g_loss: 9.4710\n",
      "Epoch 59/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0527 - g_loss: 8.4324\n",
      "Epoch 60/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0360 - g_loss: 8.3735\n",
      "Epoch 61/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0446 - g_loss: 8.9948\n",
      "Epoch 62/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.0446 - g_loss: 9.5449\n",
      "Epoch 63/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0448 - g_loss: 9.7815\n",
      "Epoch 64/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0415 - g_loss: 8.8698\n",
      "Epoch 65/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0329 - g_loss: 9.8103\n",
      "Epoch 66/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0313 - g_loss: 9.5648\n",
      "Epoch 67/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0484 - g_loss: 9.8357\n",
      "Epoch 68/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0491 - g_loss: 9.5555\n",
      "Epoch 69/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.1145 - g_loss: 9.4402\n",
      "Epoch 70/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0357 - g_loss: 9.8137\n",
      "Epoch 71/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.0413 - g_loss: 10.3961\n",
      "Epoch 72/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.0299 - g_loss: 10.7131\n",
      "Epoch 73/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0387 - g_loss: 9.7512\n",
      "Epoch 74/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.0289 - g_loss: 9.8587\n",
      "Epoch 75/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0338 - g_loss: 10.2268\n",
      "Epoch 76/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.0388 - g_loss: 9.9377\n",
      "Epoch 77/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0439 - g_loss: 10.5393\n",
      "Epoch 78/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.0564 - g_loss: 10.3460\n",
      "Epoch 79/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0324 - g_loss: 10.5636\n",
      "Epoch 80/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.0329 - g_loss: 10.5355\n",
      "Epoch 81/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0354 - g_loss: 10.4637\n",
      "Epoch 82/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.0435 - g_loss: 11.2182\n",
      "Epoch 83/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - d_loss: 0.0270 - g_loss: 10.9449\n",
      "Epoch 84/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0330 - g_loss: 11.4313\n",
      "Epoch 85/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0363 - g_loss: 11.4177\n",
      "Epoch 86/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0453 - g_loss: 10.8136\n",
      "Epoch 87/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0314 - g_loss: 11.0127\n",
      "Epoch 88/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0226 - g_loss: 11.3980\n",
      "Epoch 89/200\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 116ms/step - d_loss: 0.0382 - g_loss: 12.3248\n",
      "Epoch 90/200\n",
      "\u001b[1m  6/473\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 117ms/step - d_loss: 0.0024 - g_loss: 9.0868    "
     ]
    }
   ],
   "source": [
    "# Create the discriminator.\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((512, 512, discriminator_in_channels)),\n",
    "        #layers.Conv2D(16, (4, 4), strides=(2, 2), padding=\"same\"), \n",
    "        #layers.LeakyReLU(negative_slope=0.2),\n",
    "        #layers.Dropout(0.4),\n",
    "        \n",
    "        layers.Conv2D(64, kernel_size=4, strides=2, padding='same'),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        layers.Conv2D(128, kernel_size=4, strides=2, padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        layers.Conv2D(256, kernel_size=4, strides=2, padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        layers.Conv2D(512, kernel_size=4, strides=2, padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        layers.Conv2D(1024, kernel_size=4, strides=2, padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        #layers.Dense(128, activation='relu'), # NOW\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "\n",
    "# Create the generator.\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        #keras.layers.InputLayer((generator_in_channels,)),\n",
    "        \n",
    "        # Increase feature map size\n",
    "        layers.Dense(8 * 8 * 512, input_dim=generator_in_channels, use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "        layers.Reshape((8, 8, 512)),\n",
    "\n",
    "        # Upsample progressively to 512x512\n",
    "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "\n",
    "        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "        \n",
    "        layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "        \n",
    "        layers.Conv2DTranspose(32, kernel_size=4, strides=2, padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "        \n",
    "        layers.Conv2DTranspose(16, kernel_size=4, strides=2, padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "\n",
    "        layers.Conv2DTranspose(8, kernel_size=4, strides=2, padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "        \n",
    "        layers.Conv2DTranspose(1, kernel_size=3, strides=1, padding='same', activation='tanh')\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "\n",
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.seed_generator = keras.random.SeedGenerator(42)\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        global n_epoch, output_dir\n",
    "        # Unpack the data.\n",
    "        real_images, one_hot_labels = data\n",
    "\n",
    "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
    "        # the images. This is for the discriminator.\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        image_one_hot_labels = ops.repeat(\n",
    "            image_one_hot_labels, repeats=[image_size * image_size]\n",
    "        )\n",
    "        image_one_hot_labels = ops.reshape(\n",
    "            image_one_hot_labels, (-1, image_size, image_size, num_classes)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = ops.shape(real_images)[0]\n",
    "        random_latent_vectors = keras.random.normal(\n",
    "            shape=(batch_size, self.latent_dim), seed=self.seed_generator\n",
    "        )\n",
    "        random_vector_labels = ops.concatenate(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "\n",
    "        # Combine them with real images. Note that we are concatenating the labels\n",
    "        # with these images here.\n",
    "        fake_image_and_labels = ops.concatenate(\n",
    "            [generated_images, image_one_hot_labels], -1\n",
    "        )\n",
    "        real_image_and_labels = ops.concatenate([real_images, image_one_hot_labels], -1)\n",
    "        combined_images = ops.concatenate(\n",
    "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
    "        )\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        labels = ops.concatenate(\n",
    "            [ops.ones((batch_size, 1)), ops.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = keras.random.normal(\n",
    "            shape=(batch_size, self.latent_dim), seed=self.seed_generator\n",
    "        )\n",
    "        random_vector_labels = ops.concatenate(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = ops.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_image_and_labels = ops.concatenate(\n",
    "                [fake_images, image_one_hot_labels], -1\n",
    "            )\n",
    "            predictions = self.discriminator(fake_image_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "        \n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "\n",
    "cond_gan = ConditionalGAN(\n",
    "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
    ")\n",
    "\n",
    "print_callback = CustomCallback(generator=generator)\n",
    "\n",
    "initial_lr_generator = 0.0002\n",
    "lr_schedule_generator = ExponentialDecay(\n",
    "    initial_learning_rate=initial_lr_generator,\n",
    "    decay_steps=750,    # Adjust based on your training iterations\n",
    "    decay_rate=0.96,\n",
    "    staircase=True\n",
    ")\n",
    "generator_optimizer = keras.optimizers.Adam(learning_rate=initial_lr_generator, beta_1=0.5)\n",
    "\n",
    "initial_lr_discriminator = 0.0001\n",
    "lr_schedule_discriminator = ExponentialDecay(\n",
    "    initial_learning_rate=initial_lr_discriminator,\n",
    "    decay_steps=750,    # Adjust as needed\n",
    "    decay_rate=0.96,\n",
    "    staircase=True\n",
    ")\n",
    "discriminator_optimizer = keras.optimizers.Adam(learning_rate=initial_lr_discriminator, beta_1=0.5)\n",
    "\n",
    "\n",
    "cond_gan.compile(\n",
    "    d_optimizer=discriminator_optimizer,\n",
    "    g_optimizer=generator_optimizer,\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "cond_gan.fit(image_generator, epochs=200, callbacks=[print_callback])\n",
    "\n",
    "trained_gen = cond_gan.generator\n",
    "\n",
    "# Choose the number of intermediate images that would be generated in\n",
    "# between the interpolation + 2 (start and last images).\n",
    "num_interpolation = 9  # @param {type:\"integer\"}\n",
    "\n",
    "# Sample noise for the interpolation.\n",
    "interpolation_noise = keras.random.normal(shape=(1, latent_dim))\n",
    "interpolation_noise = ops.repeat(interpolation_noise, repeats=num_interpolation)\n",
    "interpolation_noise = ops.reshape(interpolation_noise, (num_interpolation, latent_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T09:12:44.982374Z",
     "iopub.status.busy": "2025-02-10T09:12:44.982084Z",
     "iopub.status.idle": "2025-02-10T09:12:46.885789Z",
     "shell.execute_reply": "2025-02-10T09:12:46.884991Z",
     "shell.execute_reply.started": "2025-02-10T09:12:44.982351Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738ms/step\n"
     ]
    }
   ],
   "source": [
    "def interpolate_class(first_number, second_number):\n",
    "    # Convert the start and end labels to one-hot encoded vectors.\n",
    "    first_label = keras.utils.to_categorical([first_number], num_classes)\n",
    "    second_label = keras.utils.to_categorical([second_number], num_classes)\n",
    "    first_label = ops.cast(first_label, \"float32\")\n",
    "    second_label = ops.cast(second_label, \"float32\")\n",
    "\n",
    "    # Calculate the interpolation vector between the two labels.\n",
    "    percent_second_label = ops.linspace(0, 1, num_interpolation)[:, None]\n",
    "    percent_second_label = ops.cast(percent_second_label, \"float32\")\n",
    "    interpolation_labels = (\n",
    "        first_label * (1 - percent_second_label) + second_label * percent_second_label\n",
    "    )\n",
    "\n",
    "    # Combine the noise and the labels and run inference with the generator.\n",
    "    noise_and_labels = ops.concatenate([interpolation_noise, interpolation_labels], 1)\n",
    "    fake = trained_gen.predict(noise_and_labels)\n",
    "    return fake\n",
    "\n",
    "\n",
    "start_class = 0  # @param {type:\"slider\", min:0, max:9, step:1}\n",
    "end_class = 4  # @param {type:\"slider\", min:0, max:9, step:1}\n",
    "\n",
    "fake_images = interpolate_class(start_class, end_class)\n",
    "\n",
    "fake_images *= 255.0\n",
    "converted_images = fake_images.astype(np.uint8)\n",
    "converted_images = ops.image.resize(converted_images, (512, 512)).numpy().astype(np.uint8)\n",
    "imageio.mimsave(\"animation.gif\", converted_images[:, :, :, 0], fps=1)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6640665,
     "sourceId": 10713730,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
